# Slide 6: Why Daily Limits Aren't Handled Proactively

## The Daily Limit Challenge

### âŒ The Problem: No Daily Limit Headers

**What OpenAI Sends:**
```
x-ratelimit-limit-requests: 3500        â† Minute limit (RPM)
x-ratelimit-remaining-requests: 35      â† Minute remaining
x-ratelimit-reset-requests: 6m0s        â† Minute reset

x-ratelimit-limit-tokens: 90000         â† Minute limit (TPM)
x-ratelimit-remaining-tokens: 10000     â† Minute remaining
x-ratelimit-reset-tokens: 6m0s          â† Minute reset
```

**What OpenAI Does NOT Send:**
```
x-ratelimit-limit-day: 10000            â† Daily limit (RPD) - MISSING
x-ratelimit-remaining-day: 5000         â† Daily remaining - MISSING
x-ratelimit-reset-day: 12h30m0s         â† Daily reset - MISSING
```

### Why We Can't Monitor What We Can't See

**1. Daily Limits Exist But Are Server-Side Only**
- OpenAI enforces RPD (requests per day) and TPD (tokens per day)
- Tier 2: 10,000 requests/day, 5,000,000 tokens/day
- BUT: These values are NOT exposed in API response headers

**2. Cannot Proactively Monitor**
```python
def _discover_all_limits(self, headers):
    # Finds: x-ratelimit-remaining-requests âœ…
    # Finds: x-ratelimit-remaining-tokens âœ…
    # Finds: x-ratelimit-remaining-day âŒ (doesn't exist in headers)
```

**3. Cannot Prevent Daily 429s**
- âŒ No visibility into daily usage
- âŒ No way to know how many requests left today
- âŒ Cannot calculate when daily limit will be hit
- âŒ Cannot proactively pause before hitting daily limit

### âœ… Fallback Strategy: Garak's @backoff Decorator

**Daily limits handled reactively (same as before):**

```python
@backoff.on_exception(
    backoff.fibo,
    openai.RateLimitError,  â† Catches daily limit 429s
    max_value=70,
)
def _call_model(self, ...):
    # If daily limit hit â†’ 429 error
    # @backoff waits using Fibonacci sequence
    # Retry after backoff period
```

**This works because:**
- âœ… @backoff is still active in wrapper
- âœ… Handles ANY 429 error (minute or daily)
- âœ… Same behavior as original garak
- âœ… No degradation for daily limit handling

### â„¹ï¸ Edge Case Analysis

**When do users hit daily limits?**

| Scan Type | Requests/Day | Hits Daily Limit? |
|-----------|--------------|-------------------|
| Small scan (10 probes, 100 gen) | ~1,000 | âŒ No (10% of 10k) |
| Medium scan (50 probes, 100 gen) | ~5,000 | âŒ No (50% of 10k) |
| Large scan (all probes, 100 gen) | ~20,000+ | âš ï¸ Maybe (200% of 10k) |
| Continuous scanning (24/7) | High | âœ… Yes |

**Reality:** Most users won't hit daily limits in a single scan session

### Option 1: Configuration-Based Tracking (NOT IMPLEMENTED)

**Could implement:**
```python
class OpenAIRatedGenerator(OpenAIGenerator):
    def __init__(self, ...):
        self.daily_request_count = 0
        self.daily_token_count = 0
        self.daily_reset_time = time.time() + 86400

    def _check_daily_limits(self):
        if time.time() > self.daily_reset_time:
            self.daily_request_count = 0
            self.daily_token_count = 0
            self.daily_reset_time = time.time() + 86400

        if self.daily_request_count >= 10000:
            wait_time = self.daily_reset_time - time.time()
            time.sleep(wait_time)
```

**Why NOT implemented:**

1. **Over-Engineered for Edge Case**
   - Most scans won't hit 10,000 requests/day
   - Complex state management for rare scenario
   - Violates CLAUDE.md principle: "No Over Engineering"

2. **State Management Complexity**
   - Need persistent storage (config file or database)
   - Handle process restarts, parallel execution
   - Synchronization across multiple instances
   - Daily reset time zone handling

3. **Limited Accuracy**
   - Can't account for requests made from other clients
   - Can't account for requests before garak started
   - OpenAI's daily window may not align with ours
   - Still need @backoff as fallback anyway

4. **Minimal Benefit**
   - @backoff already handles daily 429s
   - Works same as original garak
   - No user complaints about daily limit handling
   - Edge case doesn't justify complexity

### ğŸ“‹ Decision Matrix

| Approach | Pros | Cons | Decision |
|----------|------|------|----------|
| **Reactive (@backoff)** | âœ… Simple<br>âœ… Already works<br>âœ… No state management | âš ï¸ Doesn't prevent daily 429s | âœ… **CURRENT** |
| **Config-based tracking** | âœ… Could prevent some daily 429s | âŒ Complex<br>âŒ Inaccurate<br>âŒ Edge case<br>âŒ Over-engineered | âŒ Rejected |
| **Wait for OpenAI headers** | âœ… Accurate<br>âœ… Simple if available | âŒ OpenAI doesn't provide<br>âŒ Unknown if/when they will | â³ Future |

### ğŸ¯ Conclusion

**Decision:** Defer daily limit tracking until proven user need

**Rationale:**
1. OpenAI doesn't expose daily limits in headers â†’ Cannot monitor proactively
2. @backoff already handles daily 429s reactively â†’ No degradation
3. Most scans won't hit 10,000+ requests/day â†’ Edge case
4. Config-based tracking is over-engineered â†’ Violates design principles
5. Complexity not justified by benefit â†’ YAGNI principle

**Future Path:**
- âœ… If OpenAI adds daily limit headers â†’ Automatically detected (dynamic discovery)
- âœ… If users report frequent daily hits â†’ Revisit config-based approach
- âœ… For now â†’ Keep it simple, focus on minute limits (99% of use cases)
